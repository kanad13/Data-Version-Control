{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Introduction to Data Version Control (DVC)](#toc1_)    \n",
    "    - [What is DVC?](#toc1_1_1_)    \n",
    "    - [What Does This Notebook Cover?](#toc1_1_2_)    \n",
    "    - [What Can DVC Be Used For?](#toc1_1_3_)    \n",
    "    - [DVC Benefits](#toc1_1_4_)    \n",
    "- [Evolution of Versioning](#toc2_)    \n",
    "    - [Versioning with file names](#toc2_1_1_)    \n",
    "    - [Git benefits for Code Files](#toc2_1_2_)    \n",
    "    - [Git limitations for Big Data](#toc2_1_3_)    \n",
    "    - [Data Version Control](#toc2_1_4_)    \n",
    "    - [Git & DVC together](#toc2_1_5_)    \n",
    "- [DVC Basics](#toc3_)    \n",
    "    - [Initialize DVC repository](#toc3_1_1_)    \n",
    "    - [DVC Get](#toc3_1_2_)    \n",
    "    - [DVC Add & Commit](#toc3_1_3_)    \n",
    "    - [DVC Remotes](#toc3_1_4_)    \n",
    "    - [DVC Push](#toc3_1_5_)    \n",
    "    - [Tracking Data files with DVC](#toc3_1_6_)    \n",
    "- [Experiment Tracking](#toc4_)    \n",
    "    - [Machine Learning Workflow](#toc4_1_1_)    \n",
    "    - [ML Pipeline](#toc4_1_2_)    \n",
    "    - [Experiment Versions](#toc4_1_3_)    \n",
    "    - [Reproducibility](#toc4_1_4_)    \n",
    "    - [Experiment Tracking with DVC](#toc4_1_5_)    \n",
    "    - [Comparison of Experiments Tracking methods](#toc4_1_6_)    \n",
    "    - [DVCLive](#toc4_1_7_)    \n",
    "    - [DVC Studio](#toc4_1_8_)    \n",
    "    - [DVCLive Demo](#toc4_1_9_)    \n",
    "- [DVC Pipelines](#toc5_)    \n",
    "    - [Need for DVC Pipelines](#toc5_1_1_)    \n",
    "    - [Demo DVC Pipeline](#toc5_1_2_)    \n",
    "    - [Another repository](#toc5_1_3_)    \n",
    "- [Benefits & Limitations of DVC](#toc6_)    \n",
    "  - [Benefits of DVC for Data Science and ML Teams](#toc6_1_)    \n",
    "  - [Benefits of DVC for Other Teams](#toc6_2_)    \n",
    "  - [Limitations of DVC](#toc6_3_)    \n",
    "- [Comparison of DVC with other tools](#toc7_)    \n",
    "  - [DVC comparison with standalone tools](#toc7_1_)    \n",
    "    - [MLflow](#toc7_1_1_)    \n",
    "    - [Pachyderm](#toc7_1_2_)    \n",
    "    - [Weights & Biases (wandb)](#toc7_1_3_)    \n",
    "    - [Neptune.ai](#toc7_1_4_)    \n",
    "    - [Key Takeaways - DVC vs. Standalone Tools](#toc7_1_5_)    \n",
    "  - [DVC vs. Cloud Provider Offerings](#toc7_2_)    \n",
    "    - [Google Cloud Platform (GCP)](#toc7_2_1_)    \n",
    "    - [Amazon Web Services (AWS)](#toc7_2_2_)    \n",
    "    - [Microsoft Azure](#toc7_2_3_)    \n",
    "    - [Key Takeaways - DVC vs. Cloud offerings](#toc7_2_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Introduction to Data Version Control (DVC)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[What is DVC?](#toc0_)\n",
    "\n",
    "- Data Version Control (DVC) is an open-source version control system designed to handle large datasets and machine learning models.\n",
    "- It extends the capabilities of traditional version control systems, like Git, by enabling effective tracking and management of code, data, and experiments involved in data science projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[What Does This Notebook Cover?](#toc0_)\n",
    "\n",
    "This interactive jupyter notebook serves as an introduction to DVC by covering essential commands and functionalities. It includes:\n",
    "\n",
    "- **DVC Basics:** Setting up DVC project and tracking data files with it.\n",
    "- **Experiment Tracking:** ML workflow basics, need for tracking & reproducing ML experiments.\n",
    "- **DVC Pipelines:** What are ML pipelines, how do DVC pipelines help MLOps.\n",
    "- **DVC - Pros & Cons:** When to use DVC, when to not.\n",
    "- **Compare DVC to other tools:** Techniques for tracking, comparing, and optimizing experiments.\n",
    "\n",
    "By the end of this notebook, you'll have a foundational understanding of DVC and how to integrate it into your data science workflow for better project management and collaboration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[What Can DVC Be Used For?](#toc0_)\n",
    "\n",
    "- **Data Management:** Track and version your datasets and model files, allowing you to go back to any version or state as needed.\n",
    "- **Reproducibility:** Ensure that your machine learning experiments are reproducible by keeping a history of data, model, and code.\n",
    "- **Collaboration:** Collaborate more efficiently with team members by sharing data files and experiment progress consistently.\n",
    "- **Experiment Tracking:** Manage and compare multiple experiments effectively, providing insights into model performance variations.\n",
    "- **Pipeline Automation:** Build and maintain data pipelines, defining dependencies between data processing stages, which can be executed and reproduced effortlessly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_4_'></a>[DVC Benefits](#toc0_)\n",
    "\n",
    "- **Customer**\n",
    "  - Faster Time to Market\n",
    "  - Improved Model Quality\n",
    "  - Transparency and Explainability\n",
    "- **Simplicity**\n",
    "  - Easy to learn (git-like commands)\n",
    "  - Integrates with existing tools\n",
    "  - Easy Experiment Tracking\n",
    "- **Growth**\n",
    "  - Cost efficiency\n",
    "  - Increased productivity\n",
    "  - Accelerated Experimentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains code to allow mermaid diagrams to be displayed in Jupyter notebooks.\n",
    "# Run this code cell so that the mermaid diagrams in the notebook are displayed correctly.\n",
    "# This code is unrelated to the DVC topic.\n",
    "# https://mermaid.js.org/ecosystem/tutorials.html#jupyter-integration-with-mermaid-js\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mm(graph):\n",
    "    graphbytes = graph.encode(\"utf8\")\n",
    "    base64_bytes = base64.urlsafe_b64encode(graphbytes)\n",
    "    base64_string = base64_bytes.decode(\"ascii\")\n",
    "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Evolution of Versioning](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_1_'></a>[Versioning with file names](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECgkJQVtPcmlnaW5hbCBGaWxlOiBmaWxlLnR4dF0gLS0-IEJbZmlsZV91cGRhdGVkLnR4dF0KCQlBIC0tPiBDW2ZpbGVfbGF0ZXN0LnR4dF0KCQlBIC0tPiBEW2ZpbGVfY2hhbmdlZC50eHRdCgoJCUIgLS0-IEVbV2hpY2ggdmVyc2lvbj9dCgkJQyAtLT4gRQoJCUQgLS0-IEUKCgkJRSAtLT4gRltMYXRlc3QgdmVyc2lvbj9dCgkJRSAtLT4gR1tXaGF0IGNoYW5nZXM_XQoJCUUgLS0-IEhbV2hlbiBhbmQgYnkgd2hvbT9dCgkJRSAtLT4gSVtNZXJnZSBjaGFuZ2VzP10K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD\n",
    "\t\tA[Original File: file.txt] --> B[file_updated.txt]\n",
    "\t\tA --> C[file_latest.txt]\n",
    "\t\tA --> D[file_changed.txt]\n",
    "\n",
    "\t\tB --> E[Which version?]\n",
    "\t\tC --> E\n",
    "\t\tD --> E\n",
    "\n",
    "\t\tE --> F[Latest version?]\n",
    "\t\tE --> G[What changes?]\n",
    "\t\tE --> H[When and by whom?]\n",
    "\t\tE --> I[Merge changes?]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_2_'></a>[Git benefits for Code Files](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECgkJQVtDb2RlIHZlcnNpb25pbmcgd2l0aCBHaXRdCgkJQSAtLT4gQltUcmFjayBleGFjdCBjaGFuZ2VzXQoJCUEgLS0-IENbQnJhbmNoIGFuZCBtZXJnZV0KCQlBIC0tPiBEW1RyYWNrIGNvbW1pdCBoaXN0b3J5XQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD\n",
    "\t\tA[Code versioning with Git]\n",
    "\t\tA --> B[Track exact changes]\n",
    "\t\tA --> C[Branch and merge]\n",
    "\t\tA --> D[Track commit history]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_3_'></a>[Git limitations for Big Data](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCgkJQVtWZXJzaW9uIG5vbi10ZXh0IGZpbGVzXQoJCUJbVHJhY2sgbGFyZ2UgZGF0YXNldHNdCgkJQ1tUcmFjayBleHBlcmltZW50c10KCQlEW1ZlcnNpb24gcGlwZWxpbmVzXQoJCUVbVHJhY2sgbW9kZWxzXQoKCQlBIC0tPiBCCgkJQSAtLT4gQwoJCUEgLS0-IEQKCQlBIC0tPiBFCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "\t\tA[Version non-text files]\n",
    "\t\tB[Track large datasets]\n",
    "\t\tC[Track experiments]\n",
    "\t\tD[Version pipelines]\n",
    "\t\tE[Track models]\n",
    "\n",
    "\t\tA --> B\n",
    "\t\tA --> C\n",
    "\t\tA --> D\n",
    "\t\tA --> E\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_4_'></a>[Data Version Control](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW0RWQyBGZWF0dXJlc10KICAgIEEgLS0-IEJbVmVyc2lvbnMgbGFyZ2UgZGF0YSBmaWxlc10KICAgIEEgLS0-IERbV29ya3Mgd2l0aCBHaXQgJiBjbG91ZCBzdG9yYWdlXQogICAgQSAtLT4gRVtWZXJzaW9ucyBtb2RlbHMgJiBwaXBlbGluZXNdCiAgICBBIC0tPiBGW1RyYWNrcyBleHBlcmltZW50c10K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "    A[DVC Features]\n",
    "    A --> B[Versions large data files]\n",
    "    A --> D[Works with Git & cloud storage]\n",
    "    A --> E[Versions models & pipelines]\n",
    "    A --> F[Tracks experiments]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_5_'></a>[Git & DVC together](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECgkJQVtQcm9qZWN0XSAtLT4gQltDb2RlIEZpbGVzXQoJCUEgLS0-IENbRGF0YSBGaWxlc10KCQlBIC0tPiBEW01MIE1vZGVsc10KCQlCIC0tPiBFW0dpdF0KCQlDIC0tPiBGW0RWQ10KCQlEIC0tPiBGCgkJRiAtLT4gR1tFeHRlcm5hbCBTdG9yYWdlXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD\n",
    "\t\tA[Project] --> B[Code Files]\n",
    "\t\tA --> C[Data Files]\n",
    "\t\tA --> D[ML Models]\n",
    "\t\tB --> E[Git]\n",
    "\t\tC --> F[DVC]\n",
    "\t\tD --> F\n",
    "\t\tF --> G[External Storage]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[DVC Basics](#toc0_)\n",
    "\n",
    "- This section demonstrates the basic functionality of DVC (Data Version Control).\n",
    "- These are the topics covered\n",
    "  - Initialize DVC repository\n",
    "  - Add data to DVC\n",
    "  - Diffeent tyoes of DVC remotes\n",
    "  - Compare DVC with Git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Initialize DVC repository](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Backup cell\n",
    "# Switch to the root of the repository\n",
    "#import os\n",
    "# Switch to the root of the repository\n",
    "#os.chdir('/workspaces/dvc3/')\n",
    "# Get the current directory\n",
    "#current_directory = os.getcwd()\n",
    "#print(current_directory)\n",
    "# Print the contents of the current directory\n",
    "#directory_contents = os.listdir(current_directory)\n",
    "#print(directory_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DVC repository\n",
    "\n",
    "!dvc init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECiAgICBBW2R2YyBpbml0XSAtLT4gQlsuZHZjIGRpcmVjdG9yeV0KICAgIEEgLS0-IENbLmR2Y2lnbm9yZSBmaWxlXQogICAgQiAtLT4gRFtjb25maWddCiAgICBCIC0tPiBFW2NhY2hlXQogICAgQiAtLT4gRlt0bXBdCiAgICBCIC0tPiBHWy5naXRpZ25vcmVdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD\n",
    "    A[dvc init] --> B[.dvc directory]\n",
    "    A --> C[.dvcignore file]\n",
    "    B --> D[config]\n",
    "    B --> E[cache]\n",
    "    B --> F[tmp]\n",
    "    B --> G[.gitignore]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- The `dvc init` command initializes a DVC project in the current directory.\n",
    "- This is similar to `git init` for Git, but it sets up the necessary structure for DVC to work with your data.\n",
    "- After running this command, you'll notice the following changes in your VSCode sidebar:\n",
    "  - A `.dvc` directory is created. This is where DVC stores its internal files and configurations.\n",
    "  - A `.dvcignore` file is created. This is similar to `.gitignore` but for DVC.\n",
    "- The `.dvc` directory contains:\n",
    "  - `config`: DVC configuration file.\n",
    "  - `cache`: Directory where DVC stores the unique copies of your data and models\n",
    "  - `tmp`: Directory where DVC stores temporary files.\n",
    "  - `.gitignore`: File to ignore DVC-specific files.\n",
    "- For more details, check out the detailed documentation [here](https://dvc.org/doc/command-reference/init).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check what changes `dvc init` made\n",
    "\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Stage the changes caused by `dvc init`\n",
    "\n",
    "!git add .dvc .dvcignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes and push them\n",
    "\n",
    "!git commit -m \"Initialize DVC\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[DVC Get](#toc0_)\n",
    "\n",
    "- Now, let's use `dvc get` to retrieve a file from a remote repository.\n",
    "- This is similar to `git clone` but for data files. It doesn't clone the entire repository, just the specified data.\n",
    "- The syntax is `dvc get <remote-repo> <file-path>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!dvc get https://github.com/kanad13/datasets/ video/part-monarch-metamorphosis.mp4 -o data/time-lapse.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `dvc get` command is used to download data from DVC repositories.\n",
    "  - `https://github.com/kanad13/datasets/`: The URL of the Git repository\n",
    "  - `video/part-monarch-metamorphosis.mp4`: The path to the file within the source repository\n",
    "  - `-o data/time-lapse.mp4`: The output path where the file will be saved locally\n",
    "- After running this command, you'll see a new `data` directory in your VSCode sidebar containing the `time-lapse.mp4` file.\n",
    "- We can play the file to see how it is only part of the full video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[DVC Add & Commit](#toc0_)\n",
    "\n",
    "- Now that we have a data file, let's add it to DVC and commit the changes.\n",
    "- The `dvc add` command is used to add data files to DVC. It is similar to `git add`, but for data files.\n",
    "- The `dvc commit` command is used to commit the changes to the DVC repository. It is similar to `git commit` but for data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!dvc add data/time-lapse.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- The dvc add command adds a file or directory to DVC.\n",
    "- This creates a `.dvc` file, which is a small text file containing a unique identifier of the data and a file path.\n",
    "- After running these commands, you'll notice:\n",
    "  - A part-video.mp4.dvc file is created in the data directory.\n",
    "  - The actual part-video.mp4 file is copied to the DVC cache (in .dvc/cache).\n",
    "  - The data folder gets a `.gitignore` file of its own. It is updated to ignore the actual data file.\n",
    "- **Important**\n",
    "  - DVC does not actually store your large datasets or models directly within the DVC project directory\n",
    "  - We do not commit `time-lapse.mp4` since that will go to our DVC repo\n",
    "  - The metadata about this video file is versioned alongside the source code, while the original data file is added to .gitignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the updated files to the Git repository\n",
    "\n",
    "!git add data/time-lapse.mp4.dvc data/.gitignore\n",
    "!git commit -m \"Add part video file to DVC\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_4_'></a>[DVC Remotes](#toc0_)\n",
    "\n",
    "- DVC supports multiple types of remotes to store your data and models e.g. AWS S3, Google Cloud Storage, Azure Blob Storage, etc.\n",
    "- You can add a remote using the `dvc remote add` command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!dvc remote add -d myremote gs://dvc-bucket-01\n",
    "!git add .dvc/config\n",
    "!git commit -m \"Add GCS remote\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `dvc remote add` command adds a new remote storage.\n",
    "- The `-d` flag sets it as the default remote.\n",
    "- After running these commands:\n",
    "  - The `.dvc/config` file is updated with the new remote information.\n",
    "  - We commit this change to Git to version control our DVC configuration.\n",
    "- You can now push your data to the remote using the `dvc push` command.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_5_'></a>[DVC Push](#toc0_)\n",
    "\n",
    "- The `dvc push` command is used to push data to a remote storage.\n",
    "- `dvc push` uploads the files from your local DVC cache folder to the remote storage.\n",
    "- This is similar to `git push`, but for data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Prerequisite\n",
    "\n",
    "# First login to the Google Cloud Platform (GCP) using the following command:\n",
    "# gcloud auth application-default login\n",
    "\n",
    "# List the projects\n",
    "# gcloud projects list\n",
    "\n",
    "# Set the project ID\n",
    "# gcloud config set project YOUR_PROJECT_ID\n",
    "# gcloud config set project dvc-project-436415\n",
    "\n",
    "# Set the project ID for the quota\n",
    "#gcloud auth application-default set-quota-project dvc-project-436415\n",
    "\n",
    "# Check the project ID\n",
    "# gcloud config list project\n",
    "\n",
    "# This is a quick shortcut to the bucket I created within my own GCP project -\n",
    "# https://console.cloud.google.com/storage/browser?referrer=search&project=dvc-project-436415&prefix=&forceOnBucketsSortingFiltering=true\n",
    "# You must create a similar bucket in your own GCP project to have rights to push files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!dvc push\n",
    "\n",
    "#After running `dvc push`, you won't see any changes in your local file structure, but the data will be uploaded to your GCS bucket.\n",
    "# https://console.cloud.google.com/storage/browser/dvc-bucket-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                 | DVC Get                                          | DVC Pull                                                      |\n",
    "| ----------------------- | ------------------------------------------------ | ------------------------------------------------------------- |\n",
    "| **Command Syntax**      | `dvc get <repo_url> <file_path>`                 | `dvc pull [file_path]`                                        |\n",
    "| **Purpose**             | Retrieve files from a remote location            | Synchronize entire project with remote storage of DVC project |\n",
    "| **Usage Context**       | Can be used anywhere, no DVC project required    | Must be used within an existing DVC project                   |\n",
    "| **Scope**               | Individual files or directories                  | Entire project or specific tracked files/directories          |\n",
    "| **Typical Use Case**    | One-time data retrieval, accessing external data | Ongoing project work, updating local data                     |\n",
    "| **Project Setup**       | No setup required                                | Requires initialized DVC project                              |\n",
    "| **Dependency Tracking** | Doesn't track dependencies                       | Maintains project's dependency structure                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_6_'></a>[Tracking Data files with DVC](#toc0_)\n",
    "\n",
    "- Now, let's demonstrate how DVC handles updating and tracking data files, similar to how Git tracks code changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pull a new, larger version of the file from the same repo\n",
    "!dvc get https://github.com/kanad13/datasets/ video/fully-monarch-metamorphosis.mp4 -o data/time-lapse.mp4 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- We've now downloaded a larger version of the time-lapse video, overwriting the previous file.\n",
    "- This new file is similar in content but larger in size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Add the file to DVC\n",
    "!dvc add data/time-lapse.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This command shows that the file is modified.\n",
    "!git diff ./data/time-lapse.mp4.dvc\n",
    "# Notice the changes in hash & size values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Commit changes to git\n",
    "!git add data/time-lapse.mp4.dvc\n",
    "!git commit -m \"Update time-lapse video with full version\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Push the updated data to the DVC remote\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW0dpdEh1YiBSZXBvc2l0b3J5XSAtLT58ZHZjIGdldHwgQltMb2NhbCBQcm9qZWN0XQogICAgQiAtLT58ZHZjIGFkZHwgQ1tEVkMgVHJhY2tpbmddCiAgICBDIC0tPnxnaXQgYWRkL2NvbW1pdHwgRFtHaXQgUmVwb3NpdG9yeV0KICAgIEMgLS0-fGR2YyBwdXNofCBFW0dvb2dsZSBDbG91ZCBTdG9yYWdlXQoKICAgIHN1YmdyYXBoIExvY2FsIFByb2plY3QKICAgIEIKICAgIEMKICAgIEQKICAgIGVuZAoKICAgIHN1YmdyYXBoIFJlbW90ZSBTdG9yYWdlCiAgICBBCiAgICBFCiAgICBlbmQK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "    A[GitHub Repository] -->|dvc get| B[Local Project]\n",
    "    B -->|dvc add| C[DVC Tracking]\n",
    "    C -->|git add/commit| D[Git Repository]\n",
    "    C -->|dvc push| E[Google Cloud Storage]\n",
    "\n",
    "    subgraph Local Project\n",
    "    B\n",
    "    C\n",
    "    D\n",
    "    end\n",
    "\n",
    "    subgraph Remote Storage\n",
    "    A\n",
    "    E\n",
    "    end\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECiAgICBBW1Byb2plY3QgRGlyZWN0b3J5XSAtLT4gQntGaWxlIFR5cGU_fQogICAgQiAtLT58TGFyZ2UgRGF0YSBGaWxlfCBDW0RWQyBBZGRdCiAgICBCIC0tPnxDb2RlL1NtYWxsIEZpbGV8IERbR2l0IEFkZF0KICAgIEMgLS0-IEVbQ3JlYXRlcyAuZHZjIGZpbGVdCiAgICBFIC0tPiBGW0FkZCAuZHZjIGZpbGUgdG8gR2l0XQogICAgQyAtLT4gR1tBZGQgb3JpZ2luYWwgZmlsZSB0byAuZ2l0aWdub3JlXQogICAgRCAtLT4gSFtDb21taXQgdG8gR2l0IHJlcG9zaXRvcnldCiAgICBGIC0tPiBICiAgICBHIC0tPiBICiAgICBDIC0tPiBJW1N0b3JlIGRhdGEgaW4gRFZDIHJlbW90ZV0KICAgIEkgLS0-IEpbUHVzaCB0byBEVkMgcmVtb3RlXQogICAgSCAtLT4gS1tQdXNoIHRvIEdpdCByZW1vdGVdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD\n",
    "    A[Project Directory] --> B{File Type?}\n",
    "    B -->|Large Data File| C[DVC Add]\n",
    "    B -->|Code/Small File| D[Git Add]\n",
    "    C --> E[Creates .dvc file]\n",
    "    E --> F[Add .dvc file to Git]\n",
    "    C --> G[Add original file to .gitignore]\n",
    "    D --> H[Commit to Git repository]\n",
    "    F --> H\n",
    "    G --> H\n",
    "    C --> I[Store data in DVC remote]\n",
    "    I --> J[Push to DVC remote]\n",
    "    H --> K[Push to Git remote]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Experiment Tracking](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_1_'></a>[Machine Learning Workflow](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECiAgICBBW0RhdGEgTWFuYWdlbWVudCAmIEFuYWx5c2lzXSAtLT4gQltCdWlsZCAmIEV4cGVyaW1lbnRdCiAgICBCIC0tPiBDW1NvbHV0aW9uIERldmVsb3BtZW50ICYgVGVzdF0KICAgIEMgLS0-IERbRGVwbG95bWVudCAmIFNlcnZpbmddCiAgICBEIC0tPiBFW01vbml0b3IgJiBNYWludGFpbl0KICAgIEUgLS4tPiBBCiAgICBCIC0uLT4gQQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD\n",
    "    A[Data Management & Analysis] --> B[Build & Experiment]\n",
    "    B --> C[Solution Development & Test]\n",
    "    C --> D[Deployment & Serving]\n",
    "    D --> E[Monitor & Maintain]\n",
    "    E -.-> A\n",
    "    B -.-> A\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_2_'></a>[ML Pipeline](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Experiment Tracking means - Tracking details of a several runs of Machine Learning pipeline.\n",
    "\n",
    "- **Items that can be tracked include**\n",
    "\n",
    "  - hyperparameters\n",
    "  - metrics like accuracy, loss, etc.\n",
    "  - different versions of models and datasets.\n",
    "\n",
    "- **Experiment Tracking is useful for**\n",
    "  - `Compare` - Compare between different runs and models.\n",
    "  - `Track` - Track results and performance metrics.\n",
    "  - `Reproduce` - Replicate experiments using stored models, hyperparameters, etc.\n",
    "  - `Audit` - Maintain history of input data used, model used, etc.\n",
    "  - `Collaborate` - Share results and allow team members to reproduce experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBEYXRhWygiRGF0YSIpXQogICAgUGFyYW1zWUFNTFsoInBhcmFtcy55YW1sIildCgogICAgc3ViZ3JhcGggUGlwZWxpbmUKICAgICAgICBEYXRhTG9hZFsiZGF0YV9sb2FkIl0KICAgICAgICBGZWF0dXJpemVbImZlYXR1cml6ZSJdCiAgICAgICAgRGF0YVNwbGl0WyJkYXRhX3NwbGl0Il0KICAgICAgICBFdmFsdWF0ZVsiRXZhbHVhdGUiXQogICAgICAgIFRyYWluWyJUcmFpbiJdCiAgICBlbmQKCiAgICBNZXRyaWNzUGxvdHNbIk1ldHJpY3MgJiBQbG90cyJdCiAgICBNb2RlbFsiTW9kZWwiXQoKICAgIERhdGEgLS0-IERhdGFMb2FkCiAgICBEYXRhTG9hZCAtLT4gRmVhdHVyaXplCiAgICBGZWF0dXJpemUgLS0-IERhdGFTcGxpdAogICAgRGF0YVNwbGl0IC0tPiBFdmFsdWF0ZQogICAgRGF0YVNwbGl0IC0tPiBUcmFpbgogICAgRXZhbHVhdGUgLS0-IE1ldHJpY3NQbG90cwogICAgVHJhaW4gLS0-IE1vZGVsCgogICAgUGFyYW1zWUFNTCAtLi0-IFBpcGVsaW5lCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "    Data[(\"Data\")]\n",
    "    ParamsYAML[(\"params.yaml\")]\n",
    "\n",
    "    subgraph Pipeline\n",
    "        DataLoad[\"data_load\"]\n",
    "        Featurize[\"featurize\"]\n",
    "        DataSplit[\"data_split\"]\n",
    "        Evaluate[\"Evaluate\"]\n",
    "        Train[\"Train\"]\n",
    "    end\n",
    "\n",
    "    MetricsPlots[\"Metrics & Plots\"]\n",
    "    Model[\"Model\"]\n",
    "\n",
    "    Data --> DataLoad\n",
    "    DataLoad --> Featurize\n",
    "    Featurize --> DataSplit\n",
    "    DataSplit --> Evaluate\n",
    "    DataSplit --> Train\n",
    "    Evaluate --> MetricsPlots\n",
    "    Train --> Model\n",
    "\n",
    "    ParamsYAML -.-> Pipeline\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_3_'></a>[Experiment Versions](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdpdEdyYXBoCiAgICBjb21taXQgaWQ6ICJJbml0aWFsIgogICAgYnJhbmNoIGV4cGVyaW1lbnQtMQogICAgY2hlY2tvdXQgZXhwZXJpbWVudC0xCiAgICBjb21taXQgaWQ6ICJFeHAgMSAtIHYxIgogICAgY29tbWl0IGlkOiAiRXhwIDEgLSB2MiIKICAgIGNoZWNrb3V0IG1haW4KICAgIG1lcmdlIGV4cGVyaW1lbnQtMQogICAgYnJhbmNoIGV4cGVyaW1lbnQtMgogICAgY2hlY2tvdXQgZXhwZXJpbWVudC0yCiAgICBjb21taXQgaWQ6ICJFeHAgMiAtIHYxIgogICAgY2hlY2tvdXQgbWFpbgogICAgYnJhbmNoIGV4cGVyaW1lbnQtMwogICAgY2hlY2tvdXQgZXhwZXJpbWVudC0zCiAgICBjb21taXQgaWQ6ICJFeHAgMyAtIHYxIgogICAgY2hlY2tvdXQgZXhwZXJpbWVudC0yCiAgICBjb21taXQgaWQ6ICJFeHAgMiAtIHYyIgogICAgY2hlY2tvdXQgbWFpbgogICAgbWVyZ2UgZXhwZXJpbWVudC0yCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "gitGraph\n",
    "    commit id: \"Initial\"\n",
    "    branch experiment-1\n",
    "    checkout experiment-1\n",
    "    commit id: \"Exp 1 - v1\"\n",
    "    commit id: \"Exp 1 - v2\"\n",
    "    checkout main\n",
    "    merge experiment-1\n",
    "    branch experiment-2\n",
    "    checkout experiment-2\n",
    "    commit id: \"Exp 2 - v1\"\n",
    "    checkout main\n",
    "    branch experiment-3\n",
    "    checkout experiment-3\n",
    "    commit id: \"Exp 3 - v1\"\n",
    "    checkout experiment-2\n",
    "    commit id: \"Exp 2 - v2\"\n",
    "    checkout main\n",
    "    merge experiment-2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_4_'></a>[Reproducibility](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBzdWJncmFwaCBEZXZlbG9wbWVudCBFbnZpcm9ubWVudAogICAgQVtIaXN0b3JpY2FsIERhdGFdIC0tPiBCW0ZlYXR1cmUgRW5naW5lZXJpbmddCiAgICBCIC0tPiBDW1RyYWluXQogICAgQyAtLT4gRFtTY29yaW5nXQogICAgRCAtLT4gRVtQcmVkaWN0aW9uc10KICAgIEMgLS0-IEZbTW9kZWxdCiAgICBlbmQKCiAgICBzdWJncmFwaCBQcm9kdWN0aW9uIEVudmlyb25tZW50CiAgICBHW0xpdmUgRGF0YV0gLS0-IEhbRmVhdHVyZSBFbmdpbmVlcmluZ10KICAgIEggLS0-IElbU2NvcmluZ10KICAgIEkgLS0-IEpbUHJlZGljdGlvbnNdCiAgICBlbmQKCiAgICBGIC0tPiBJCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "    subgraph Development Environment\n",
    "    A[Historical Data] --> B[Feature Engineering]\n",
    "    B --> C[Train]\n",
    "    C --> D[Scoring]\n",
    "    D --> E[Predictions]\n",
    "    C --> F[Model]\n",
    "    end\n",
    "\n",
    "    subgraph Production Environment\n",
    "    G[Live Data] --> H[Feature Engineering]\n",
    "    H --> I[Scoring]\n",
    "    I --> J[Predictions]\n",
    "    end\n",
    "\n",
    "    F --> I\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_5_'></a>[Experiment Tracking with DVC](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW1JhdyBEYXRhXSAtLT4gQltEYXRhIFByZXBhcmF0aW9uXQogICAgQiAtLT4gQ1tGZWF0dXJlIEVuZ2luZWVyaW5nXQogICAgQyAtLT4gRFtNb2RlbCBUcmFpbmluZ10KICAgIEQgLS0-IEVbTW9kZWwgRXZhbHVhdGlvbl0KICAgIEUgLS0-IEZbTW9kZWwgRGVwbG95bWVudF0KCiAgICBzdWJncmFwaCBEVkMgVHJhY2tpbmcKICAgIEdbVmVyc2lvbiBDb250cm9sXQogICAgSFtNZXRyaWNzIExvZ2dpbmddCiAgICBJW0h5cGVycGFyYW1ldGVyIFRyYWNraW5nXQogICAgZW5kCgogICAgQiAtLi0-IEcKICAgIEMgLS4tPiBHCiAgICBEIC0uLT4gRwogICAgRCAtLi0-IEkKICAgIEUgLS4tPiBICg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "    A[Raw Data] --> B[Data Preparation]\n",
    "    B --> C[Feature Engineering]\n",
    "    C --> D[Model Training]\n",
    "    D --> E[Model Evaluation]\n",
    "    E --> F[Model Deployment]\n",
    "\n",
    "    subgraph DVC Tracking\n",
    "    G[Version Control]\n",
    "    H[Metrics Logging]\n",
    "    I[Hyperparameter Tracking]\n",
    "    end\n",
    "\n",
    "    B -.-> G\n",
    "    C -.-> G\n",
    "    D -.-> G\n",
    "    D -.-> I\n",
    "    E -.-> H\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_6_'></a>[Comparison of Experiments Tracking methods](#toc0_)\n",
    "\n",
    "| Traditional Method     | DVC-based            |\n",
    "| ---------------------- | -------------------- |\n",
    "| Manual Logging         | Automated Tracking   |\n",
    "| Spreadsheets           | Structured Storage   |\n",
    "| Manual Version Control | Git Integration      |\n",
    "| Difficult to Reproduce | Easy Reproducibility |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_7_'></a>[DVCLive](#toc0_)\n",
    "\n",
    "- **DVCLive**\n",
    "  - It is a Python library for tracking metrics associated with machine learning experiments.\n",
    "- **Key Features**\n",
    "  - Logs metrics, parameters, plots, and artifacts during model training\n",
    "  - Integrates with popular ML frameworks (e.g., PyTorch Lightning, Scikit-learn)\n",
    "  - Provides real-time experiment logging capabilities\n",
    "  - DVCLive is an ML logger similar to MLflow. Vertex AI provides similar logging capabilities as DVCLive, but is is designed to work within the Google Cloud ecosystem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Comparison of DVCLive with other related tools**\n",
    "  - [link](https://github.com/iterative/dvclive?tab=readme-ov-file#comparison-to-related-technologies)\n",
    "  - DVCLive is an ML Logger, similar to:\n",
    "    - [MLFlow](https://mlflow.org/)\n",
    "    - [Weights & Biases](https://wandb.ai/site)\n",
    "    - [Neptune](https://neptune.ai/)\n",
    "  - The main differences with those ML Loggers are:\n",
    "    - DVCLive does not require any additional services or servers to run.\n",
    "    - DVCLive metrics, parameters, and plots are stored as plain text files that can be versioned by tools like Git or tracked as pointers to files in DVC storage.\n",
    "    - DVCLive can save experiments or runs as hidden Git commits.\n",
    "    - You can then use different options to visualize the metrics, parameters, and plots across experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_8_'></a>[DVC Studio](#toc0_)\n",
    "\n",
    "- **DVC Studio**\n",
    "  - It is a web-based platform for managing and visualizing experiments tracked with DVC.\n",
    "- **Key Features**\n",
    "  - Provides a user interface for viewing, comparing, and analyzing DVC experiments\n",
    "  - Visualizes plots, metrics, and other experiment data in a centralized dashboard\n",
    "  - Enables real-time monitoring of ongoing experiments when integrated with DVCLive\n",
    "- **Integration between DVCLive and DVC Studio**\n",
    "  - `DVCLive` - Tool for logging experiment data during training\n",
    "  - `DVC Studio` - Platform for visualizing and managing that data\n",
    "  - `Together` - In DVC Studio, users can see live updates of metrics and plots as they're being logged by DVCLive, allowing for real-time monitoring of ongoing experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_9_'></a>[DVCLive Demo](#toc0_)\n",
    "\n",
    "- **DVCLive in action**\n",
    "  - We will now execute a script that simulates a machine learning training process.\n",
    "  - It demonstrates how to use DVC Live to log parameters and metrics.\n",
    "  - It creates fake accuracy and loss values that mimic typical ML training behavior over multiple epochs.\n",
    "- **DVCStudio in action**\n",
    "  - Run this code 3-4 times to simulate different training runs. Use different parameters to see how they affect the results.\n",
    "  - Once you have run this code a few times, you can view the results in the DVCLive dashboard. And also on DVCStudio.\n",
    "  - DVCStudio allows you to share and visualize your DVC experiments with others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- **Prerequisites**\n",
    "- Go to DVC Studio and create a DVC project. Grant access to your repo from that project.\n",
    "- Connect vscode and DVC Studio by clicking the Get Token from inside DVCStudio page in DVC extension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from dvclive import Live\n",
    "\n",
    "# Define hyperparameters for the simulated training\n",
    "params = {\"learning_rate\": 0.002, \"optimizer\": \"Adam\", \"epochs\": 11}\n",
    "\n",
    "# Start a DVC Live session\n",
    "with Live() as live:\n",
    "    # Log the hyperparameters\n",
    "    for param in params:\n",
    "        live.log_param(param, params[param])\n",
    "\n",
    "    # Generate a random offset to add variability to the simulated metrics\n",
    "    offset = random.uniform(0.2, 0.1)\n",
    "\n",
    "    # Simulate the training process\n",
    "    for epoch in range(1, params[\"epochs\"]):\n",
    "        # Generate a random \"fuzz\" value to add noise to the metrics\n",
    "        fuzz = random.uniform(0.01, 0.1)\n",
    "        # Calculate simulated accuracy (increases over time)\n",
    "        accuracy = 1 - (2 ** - epoch) - fuzz - offset\n",
    "        # Calculate simulated loss (decreases over time)\n",
    "        loss = (2 ** - epoch) + fuzz + offset\n",
    "        # Log the accuracy metric\n",
    "        live.log_metric(\"accuracy\", accuracy)\n",
    "        # Log the loss metric\n",
    "        live.log_metric(\"loss\", loss)\n",
    "        # Move to the next step (epoch) in DVC Live\n",
    "        live.next_step()\n",
    "        # Add a small delay to simulate the time taken for each epoch\n",
    "        time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git add .\n",
    "!git commit -m \"next run\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **IMPORTANT**\n",
    "  - Commit after each run for best results.\n",
    "  - DVCLive will show the metrics for each run and you can compare them by selecting the commits from the drop-down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- **More about DVCLive**\n",
    "  - DVCLive relies on Git to track the generated directory\n",
    "  - After you run your training code above, all the logged data will be stored in the dvclive directory and tracked as a DVC experiment for analysis and comparison.\n",
    "  - DVCLive tracks different metrics and artifacts in specific locations within a directory structure:\n",
    "    - Metrics:\n",
    "      - General metrics: `/plots/metrics`\n",
    "      - System metrics: `dvclive/plots/metrics/system`\n",
    "    - Parameters: `dvclive/params.yaml`\n",
    "    - Images: `dvclive/plots/images`\n",
    "    - Custom plots: `dvclive/plots/custom`\n",
    "    - Sklearn plots: `dvclive/plots/sklearn`\n",
    "    - Artifacts:\n",
    "      - Default: `.dvc` files in the root directory (e.g., `model.pt.dvc`)\n",
    "      - Optional: `dvclive/artifacts/{path}` or `dvclive/artifacts/{path}.dvc`\n",
    "    - Summary: `dvclive/metrics.json`\n",
    "  - [link](https://dvc.org/doc/dvclive?tab=Parameters#outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Use DVCLive CLI to view the results\n",
    "# https://github.com/iterative/dvclive?tab=readme-ov-file#dvc-cli\n",
    "# A better way although is to use DVCStudio or the vscode extension.\n",
    "\n",
    "!dvc exp show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DVCLive CLI to view the results\n",
    "# https://github.com/iterative/dvclive?tab=readme-ov-file#dvc-cli\n",
    "# A better way although is to use DVCStudio or the vscode extension.\n",
    "\n",
    "!dvc plots diff $(dvc exp list --names-only) --open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[DVC Pipelines](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[Need for DVC Pipelines](#toc0_)\n",
    "\n",
    "- **Beyond Jupyter Notebooks**\n",
    "  - Experimenting interactively in Jupyter notebooks is great for exploration.\n",
    "  - But once you are ready to scale up your workflow, you need a more structured way to run reproducible experiments.\n",
    "- **ML Pipelines**\n",
    "  - ML Pipelines are a sequence of stages that process data and train models.\n",
    "  - They Include stages like data preprocessing, model training, evaluation, and deployment.\n",
    "- **DVC Pipelines**\n",
    "  - DVC pipelines help you version control your entire machine learning workflow, including data, code, and model artifacts.\n",
    "  - Pipeline definitions are stored in the `dvc.yaml` file, which describes the stages, their dependencies, and outputs.\n",
    "  - DVC pipelines enable `reproducibility` by tracking the entire experiment lifecycle, from raw data to final results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_2_'></a>[Demo DVC Pipeline](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- To demonstrate how to work with DVC pipelines, we are going to create a simple pipeline with the following stages:\n",
    "  - `Prepare` - Process raw data\n",
    "  - `Featurize` - Transform prepared data into feature vectors\n",
    "  - `Train` - Train a machine learning model\n",
    "  - `Evaluate` - Assess model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBBW1ByZXBhcmVdIC0tPiBCW0ZlYXR1cml6ZV0KICAgIEIgLS0-IENbVHJhaW5dCiAgICBDIC0tPiBEW0V2YWx1YXRlXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR\n",
    "    A[Prepare] --> B[Featurize]\n",
    "    B --> C[Train]\n",
    "    C --> D[Evaluate]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_3_'></a>[Another repository](#toc0_)\n",
    "\n",
    "- Navigate to this [github repository](https://github.com/kanad13/dvc-pipelines) to see the code for the pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Benefits & Limitations of DVC](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_1_'></a>[Benefits of DVC for Data Science and ML Teams](#toc0_)\n",
    "\n",
    "1. Version Control: Data, models, and code\n",
    "2. Reproducibility: Experiments and environments\n",
    "3. Collaboration: Team sharing and open-source contribution\n",
    "4. Pipeline Management: Workflow automation and dependency tracking\n",
    "5. Experiment Management: Metrics tracking and visualization\n",
    "6. Storage and Computation: Remote integration and resource optimization\n",
    "7. Flexibility: Lightweight architecture and tool integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_2_'></a>[Benefits of DVC for Other Teams](#toc0_)\n",
    "\n",
    "- **DevOps and Infrastructure**\n",
    "  - CI/CD integration for ML workflows\n",
    "  - Infrastructure as Code compatibility\n",
    "- **FinOps and Resource Management**\n",
    "  - Cost optimization and predictive modeling\n",
    "  - Resource utilization tracking\n",
    "- **Quality Assurance**\n",
    "  - Reproducible test environments\n",
    "  - Model performance validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_3_'></a>[Limitations of DVC](#toc0_)\n",
    "\n",
    "1. Learning curve for new users\n",
    "2. Limited built-in visualization tools\n",
    "3. Basic collaboration features\n",
    "4. Ecosystem fragmentation in MLOps toolchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Comparison of DVC with other tools](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_1_'></a>[DVC comparison with standalone tools](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_1_'></a>[MLflow](#toc0_)\n",
    "\n",
    "| **Aspect**          | **MLflow**                                                                 | **DVC**                                                       |\n",
    "| ------------------- | -------------------------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| **Purpose**         | Primarily focused on experiment tracking, model management, and deployment | Focused on data version control and pipeline management       |\n",
    "| **Key Differences** | More comprehensive UI for experiment tracking and visualization            | Integrates more closely with Git for version control          |\n",
    "| **Similarities**    | Both support experiment reproducibility, metrics & parameters              | Both support experiment reproducibility, metrics & parameters |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_2_'></a>[Pachyderm](#toc0_)\n",
    "\n",
    "| **Feature**           | **Pachyderm**                                                | **DVC**                                                               |\n",
    "| --------------------- | ------------------------------------------------------------ | --------------------------------------------------------------------- |\n",
    "| **Purpose**           | Focuses on data lineage, versioning, and pipeline automation | Focused on data version control and pipeline management               |\n",
    "| **Pipeline Approach** | Uses a container-based approach for pipeline stages          | More lightweight and integrates directly with Git                     |\n",
    "| **Scalability**       | Stronger support for large-scale data processing             | Simpler learning curve and easier integration into existing workflows |\n",
    "| **Data Management**   | Provides data versioning and pipeline management             | Provides data versioning and pipeline management                      |\n",
    "| **Collaboration**     | Supports reproducibility and collaboration                   | Supports reproducibility and collaboration                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_3_'></a>[Weights & Biases (wandb)](#toc0_)\n",
    "\n",
    "| **Feature**                       | **Weights & Biases (Wandb)**                                | **DVC**                                                       |\n",
    "| --------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| **Purpose**                       | Specializes in experiment tracking and visualization for ML | Focused on data and pipeline version control                  |\n",
    "| **Visualization & Collaboration** | More advanced visualization and collaboration features      | Integrates more closely with existing version control systems |\n",
    "| **Hosting**                       | Offers hosted solutions                                     | Self-hosted                                                   |\n",
    "| **Integration**                   | Supports tracking experiments and metrics                   | Supports tracking experiments and metrics                     |\n",
    "| **Collaboration**                 | Supports team collaboration in ML projects                  | Supports team collaboration in ML projects                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_4_'></a>[Neptune.ai](#toc0_)\n",
    "\n",
    "| **Feature**                        | **Neptune.ai**                                                       | **DVC**                                                             |\n",
    "| ---------------------------------- | -------------------------------------------------------------------- | ------------------------------------------------------------------- |\n",
    "| **Purpose**                        | Metadata store for MLOps, specialized in experiment management       | Focused on data versioning and pipeline management                  |\n",
    "| **User Interface & Collaboration** | More comprehensive UI for experiment tracking and team collaboration | Integrates more closely with Git and existing development workflows |\n",
    "| **Versioning & Tracking**          | Supports versioning and tracking of ML experiments                   | Supports versioning and tracking of ML experiments                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_5_'></a>[Key Takeaways - DVC vs. Standalone Tools](#toc0_)\n",
    "\n",
    "| Aspect                    | **DVC**                                                                    | **Standalone Tools** (MLflow, Pachyderm, W&B, Neptune.ai)                                                 |\n",
    "| ------------------------- | -------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |\n",
    "| **Purpose**               | Focused on data version control, pipeline management, and Git integration. | Primarily focused on experiment tracking, model management, and deployment, with various specializations. |\n",
    "| **Versioning & Tracking** | Git-based version control for data, pipelines, and models.                 | Focus on experiment tracking and metrics, with some supporting metadata stores and lineage.               |\n",
    "| **Pipeline Management**   | Lightweight, Git-integrated pipelines via `dvc.yaml`.                      | Varies; some offer advanced pipelines (e.g., Pachyderm's container-based approach).                       |\n",
    "| **Scalability**           | Scales with cloud storage backend integration.                             | Often better suited for large-scale workflows; some tools are cloud-hosted for added scalability.         |\n",
    "| **Collaboration**         | Git-based collaboration for data and models.                               | Advanced collaboration features, often with built-in team and UI support.                                 |\n",
    "| **Visualization**         | Limited visualization, relies on external tools.                           | Richer, built-in visualizations and dashboards (e.g., W&B excels in experiment visualization).            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[DVC vs. Cloud Provider Offerings](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_2_1_'></a>[Google Cloud Platform (GCP)](#toc0_)\n",
    "\n",
    "| Feature/Offering    | DVC                                             | GCP                                      | Integration/Comparison                                                |\n",
    "| ------------------- | ----------------------------------------------- | ---------------------------------------- | --------------------------------------------------------------------- |\n",
    "| Data Storage        | Local or remote storage                         | Google Cloud Storage                     | DVC can use Cloud Storage as a remote storage backend                 |\n",
    "| Version Control     | Git-like versioning for data and models         | No native data versioning                | DVC adds versioning capabilities to GCP storage                       |\n",
    "| Experiment Tracking | Basic experiment versioning through Git commits | AI Platform Experiments                  | DVC can complement AI Platform by versioning data used in experiments |\n",
    "| Pipeline Management | `dvc.yaml` for defining pipelines               | Cloud Composer (based on Apache Airflow) | DVC pipelines can be triggered within Cloud Composer workflows        |\n",
    "| Model Registry      | Through Git and DVC remote storage              | AI Platform Model Registry               | DVC can version model files that are registered in AI Platform        |\n",
    "| Scalability         | Depends on storage backend                      | Highly scalable cloud infrastructure     | DVC leverages GCP's scalability when using Cloud Storage              |\n",
    "| Collaboration       | Through Git and shared DVC remotes              | Various GCP collaboration tools          | DVC enhances collaboration on data and models within GCP projects     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_2_2_'></a>[Amazon Web Services (AWS)](#toc0_)\n",
    "\n",
    "| Feature/Offering    | DVC                                             | AWS                                        | Integration/Comparison                                              |\n",
    "| ------------------- | ----------------------------------------------- | ------------------------------------------ | ------------------------------------------------------------------- |\n",
    "| Data Storage        | Local or remote storage                         | Amazon S3                                  | DVC can use S3 as a remote storage backend                          |\n",
    "| Version Control     | Git-like versioning for data and models         | No native data versioning in S3            | DVC adds versioning capabilities to AWS storage                     |\n",
    "| Experiment Tracking | Basic experiment versioning through Git commits | SageMaker Experiments                      | DVC can complement SageMaker by versioning data used in experiments |\n",
    "| Pipeline Management | `dvc.yaml` for defining pipelines               | AWS Step Functions, SageMaker Pipelines    | DVC pipelines can be integrated into AWS workflow tools             |\n",
    "| Model Registry      | Through Git and DVC remote storage              | SageMaker Model Registry                   | DVC can version model files that are registered in SageMaker        |\n",
    "| Scalability         | Depends on storage backend                      | Highly scalable cloud infrastructure       | DVC leverages AWS's scalability when using S3                       |\n",
    "| Collaboration       | Through Git and shared DVC remotes              | AWS collaboration tools (e.g., CodeCommit) | DVC enhances collaboration on data and models within AWS projects   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_2_3_'></a>[Microsoft Azure](#toc0_)\n",
    "\n",
    "| Feature/Offering    | DVC                                             | Azure                                     | Integration/Comparison                                              |\n",
    "| ------------------- | ----------------------------------------------- | ----------------------------------------- | ------------------------------------------------------------------- |\n",
    "| Data Storage        | Local or remote storage                         | Azure Blob Storage                        | DVC can use Azure Blob Storage as a remote storage backend          |\n",
    "| Version Control     | Git-like versioning for data and models         | No native data versioning in Blob Storage | DVC adds versioning capabilities to Azure storage                   |\n",
    "| Experiment Tracking | Basic experiment versioning through Git commits | Azure Machine Learning                    | DVC can complement Azure ML by versioning data used in experiments  |\n",
    "| Pipeline Management | `dvc.yaml` for defining pipelines               | Azure Data Factory, ML Pipelines          | DVC pipelines can be integrated into Azure workflow tools           |\n",
    "| Model Registry      | Through Git and DVC remote storage              | Azure Machine Learning Model Registry     | DVC can version model files that are registered in Azure ML         |\n",
    "| Scalability         | Depends on storage backend                      | Highly scalable cloud infrastructure      | DVC leverages Azure's scalability when using Blob Storage           |\n",
    "| Collaboration       | Through Git and shared DVC remotes              | Azure DevOps                              | DVC enhances collaboration on data and models within Azure projects |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc7_2_4_'></a>[Key Takeaways - DVC vs. Cloud offerings](#toc0_)\n",
    "\n",
    "| Aspect                  | DVC                                                                                    | Cloud Provider Offerings                                                                                        |\n",
    "| ----------------------- | -------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |\n",
    "| **Versioning**          | Cloud-agnostic, Git-like versioning for data and models across cloud storage backends. | Limited or no native data versioning in most storage services.                                                  |\n",
    "| **Experiment Tracking** | Basic versioning via Git commits. Lacks rich experiment tracking features.             | Advanced tools (e.g., SageMaker, Google AI, Azure ML) offer detailed metrics and comparison capabilities.       |\n",
    "| **Model Registry**      | Supports model versioning but lacks deployment and lineage features.                   | Full-featured registries with advanced capabilities (e.g., SageMaker, Azure ML Model Registry).                 |\n",
    "| **Pipeline Management** | Focused on data science workflows via `dvc.yaml`.                                      | Broader workflow management, including data engineering and ETL (e.g., AWS Step Functions, Azure Data Factory). |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
